---
title: "Final Report for Red Wine Analysis"
author: "Ruiqiang Chen, Michael DeWitt, David Williams, Alex Vannoy"
date: "7/28/2017"
header-includes:
   - \usepackage{amsmath}
   - \usepackage{float}

output:
  pdf_document:
    number_sections: yes
    keep_tex: yes
  html_document:
    fig_caption: yes
    fig_height: 4
    number_sections: yes
    pandoc_args:
    - +RTS
    - -K64m
    - -RTS
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = "H")
library(ProjectTemplate)
library(ggfortify)
load.project()

(filenames <- list.files("src", pattern="*.R", full.names=TRUE))

for( a in 1:length(filenames)){
  on.exit(filenames[a])
  source(paste0(filenames[a]))
}
```

# Introduction

The purpose of this document is to report the proposed statistical models for classification of red wine bases on eleven predictors. The purpose of this analysis is to provide a model to the vintners in order for them to better predict the quality rating for their product. Analysis will be performing using both regression techniques and classification techniques.

# Description of Data
The data set provided is the Wine dataset from UC Irvine of red _vinho verde_ wine samples, from the north of Portugal [Cortez et al., 2009]. It consists of `r nrow(red_wine_data_raw) ` with a total of `r ncol(red_wine_data_raw) -1` physicochemical predictors and a response variable. These predictors include the following: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, and alcohol with the quality feature being associated with the judgement of the individual wine's quality. Quality is the feature of interest for the dataset as the vintner is interested in judging the wine's quality through objective means rather than today's subjective method of averaging the 1one to ten point judgment of taste-testers. A summary of these measures as well as the response variable can be seen in Table 1. 

```{r summary_table, echo = FALSE}
knitr::kable(table_to_print, booktabs = TRUE,
             caption = "Summary Statistics for the Wine Dataset")
```


The distribution of these different criteria can be seen below in the histograms in Figure 1.

```{r global_histograms, echo=FALSE, warning=FALSE, message=FALSE, fig.cap= "Histogram of all variables in the data set", fig.asp= .5}
red_wine_data_index <-red_wine_data_raw%>% 
  mutate(id = seq.int(nrow(red_wine_data_raw)))
as.data.frame(red_wine_data_index) %>% 
  melt(id.vars = "id") %>% 
  ggplot(aes(value))+facet_wrap(~variable, scales = "free_x")+geom_histogram()+
  geom_histogram(binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)))
```

The following are slightly right skewed: Fixed Acidity, Volatile Acidity, Citric Acid, , Free Sulfur Dioxide, Total Sulfur Dioxide, Sulphates, and Alcohol. Residual Sugar and Chlorides are heavily right skewed with density and pH appearing more normally distributed. Completing a Shapiro Wilke normality test on the components indicates that all are non-normal. Reviewing the individual components there appears to be a slight irregularity with total free sulfur dioxide. This can be seen in the histogram of free sulfur dioxide values.

```{r so2_fig, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Histogram of Sulfur Dioxide Predictor", fig.asp= 0.5}
as.data.frame(red_wine_data_factors) %>% 
  melt() %>%
  filter(variable == "free_sulfur_dioxide") %>% 
  ggplot(aes( value))+
  geom_histogram(bins = 30)+
  # labs(
  #   title = "Histogram of Free Sulfur Dioxide",
  #   caption = "From UCI Wine Data Set"
  # )+
  xlab("Free Sulfur Dioxide")
```

As well as the fit of free sulfur dioxide display high studentized residuals and leverage and thus should be considered for removal in the modeling process. These wines are 1080 and 1082.

```{r so2_resid, echo=FALSE, warnings = FALSE, fig.cap="Residual Plots of Linear Model Predicting Quality with Total Sulfur Dioxide ", fig.asp= .5}
so2_resid <-autoplot(fit2)
print(so2_resid)
```

These two wines have been removed from the clean dataset in order to be better predictors. The presence of these two wines may result in incorrect or inaccurate predictions. Ass we did not gather this dataset, we do not know if this information was incorrectly captured or if these values are real. However, given the strong indication that these two points are outliers with high leverage it is a good assumption to remove these two points.

# Method
In order to estimate the test error of any of the generated models, the data was divided in testing and training data sets with which to train then models and then test and estimate the testing error. Seventy percent of the raw data was randomly selected and placed in the training set with the remaining thirty percent used as the testing data set.

## Regression

To select the best fit regression model, several regression modeling methods were used: Least Squares Regression, Ridge Regression, Lasso Regression, Principle Components Regression, Partial Least Squares Regression, and Boosting. In each regression the dependent variable was the integer value of Quality. The data were divided into two sets, a training set to train the model and a testing set for model validation. We will now go deeper in the model generation process for each of these modeling types and methods

### Least Squares
The least squares regression method that was tested was the best subset selection. The methodology used to determine the best subset model was to first run cross-validation on the training set in order to determine the best number of predictors to include in the model. This analysis indicated that any additional predictor after three variables did not increase the accuracy of the model. The training data were then used to determine the best subset of the linear model with three predictors. The best subset included volatile acidity, sulphates, and alcohol.

#### Residual Analysis
The linear regression model requires the assumption that residuals from the model have constant, unrelated variances. The plots below show the fitted values versus the residual values and illustrate that we satisfy the assumptions required to conduct a linear regression. 

```{r residuals, echo=FALSE, warning=FALSE, message=FALSE, fig.cap= "Plot of Residuals from Linear Regression", fig.asp= .5}
print(linear_resid)
```

The residuals appear to have no distinct pattern which is a positive sign that there are not lurking relationships that have not been treated by the modeling.


### Ridge Regression
Ridge regression was performed on the dataset as well. Cross-validation was performed on the training data set to determine the optimum value for lambda for the ridge regression. This lambda, `r round(bestlam_ridge,3)` was then used in a ridge regression model with the testing dataset. Further, there seems to be a very large coefficient with 11 much smaller coefficients.

### Lasso Regression
Next Lasso regression was performed with cross-validation. We conducted cross-validation to determine the optimal value for lambda for the Lasso regression. This value was `r round(bestlam_lasso,3)`. As a function of the Lasso regression, only pH was shrunk to zero; total sulfur dioxide and free sulfur dioxide were shrunk to near zero. As was the case with ridge regression, there appears to be one large coefficient compared to the others.

```{r lasso, echo=FALSE, warning=FALSE, message=FALSE, out.width=c('225px', '225px'), fig.align = "center", fig.show = "hold", fig.cap= "Plot of Lambda vs Coefficients for Ridge/Lasso Regression"}
plot(ridge_mod, xvar = "lambda", label = TRUE, main = "Ridge Regression")
plot(lasso_mod, xvar = "lambda", label = TRUE, main = "Lasso Regression")
```


### Principal Components Regression
Next we performed Principal components regression. Analysis of the principal components revealed that 90 percent of the variation in the response could be explained by the first nine components, so we used these first nine principal components for model training. This is graphically displayed in the plot of principal components.

```{r pcr_fig, echo=FALSE, warning=FALSE, message=FALSE, fig.cap= "Variance Explained for Principal Components Regression", fig.asp= .5}
pcr_fit <- pcr( quality ~ ., data=red_wine_data_training, scale=TRUE, validation="CV" )
pcr_x<-pcr_fit$Xvar/sum(pcr_fit$Xvar)
plot(cumsum(pcr_x), xlab = "Number of Components", ylab = "Cumulative Porportion of Variance Explained", ylim = c(0,1))
```

### Partial Least Squares Regression
Next we performed partial least squares regression, using the response variable Quality as supervision over the principal components. Using this method, we see from the plot of partial least squares components that after roughly 2-3 components, model accuracy no longer substantially increases.

```{r pls_fig, echo=FALSE, warning=FALSE, message=FALSE, fig.cap= "Variance Explained for Partial Least Squares Regression", fig.asp= .5}
pls_fit <- plsr( quality ~ ., data = red_wine_data_clean, subset = train_rows, 
                 scale=TRUE, validation="CV" )
pls_x<-pls_fit$Xvar/sum(pls_fit$Xvar)
plot(cumsum(pls_x), xlab = "Number of Components", ylab = "Cumulative Porportion of Variance Explainned", ylim = c(0,1))
```

### Boosted Regression
inally we performed Boosted regression. The interaction depth was limited to four in order to reduce the likelihood of over-fitting the data. The model was trained on 5,000 different trees and we assumed a Guassian distribution.

```{r boost_importance, warning= FALSE, echo = FALSE, fig.asp= .5, fig.cap="Relative Importance from Boosted Regression", fig.pos="H"}
print(boost_reg_plot)
```

### Model Selection
The resulting mean squared errors for each regression method were tabulated in order to determine the superior model.

```{r mse_results, warning= FALSE, echo = FALSE, fig.asp= .5, fig.cap="Plot of Results of Different Regression Techniques", fig.pos="H"}
print(MSE_plot)
```

## Classification
For classification purposes the wines were segregated in to three different classes. These classes include "good" ($quality >7$), "medium" ($\; quality \; between \; 4 \;and\;  7$) and "poor"($quality < 4$). 

### Model Selection
We conducted our analysis for this new variable of quality classes using several classification models: K-Nearest Neighbors, Linear Discriminant Analysis, Quadratic Discriminant Analysis, and tree classification. We trained each model using the training data set and then applied the resulting model to the testing dataset to estimate the model's test error. It is important to note that we achieved greater accuracy by scaling values for the K-Nearest Neighbors approach, which is sensitive to scale differences across variables. Using unscaled values, the validation algorithm was best using `r unscaled_neighbours` variables; using scaled values, `r scaled_knn` were best. The larger number of neighbours makes for a much more global model: it is less sensitive to immediate neighbours in the bias-variance trade-off. The tree classification model was trained first through cross-validation and then pruned to six leaves to reduce the impact of over-fitting in the bias-variance trade-off.

## Comparison of Models
```{r classification_results, echo=FALSE, message=FALSE, warning=FALSE, fig.asp= .5, fig.cap="Plot of Results of Different Classification Techniques", fig.pos= "H"}
print(classification_plot)
```

All of these models seek to maximize the global accuracy of the model. More interesting for the vintners is the ability to detect each of the three different classes of the wines.

```{r classification_details, echo=FALSE, message=FALSE, warning=FALSE, fig.asp= .5}

knitr::kable(combined_detailed_classification_by_category, booktabs = TRUE,
             caption = "Detailed Classification Accuracy")

```

# Discussion
This analysis shows that for regression the boosted model resulted in the highest accuracy of all regression models; however, this accuracy comes at a cost of interpretability. Because the boosted algorithms have little intrepretation this accuracy is more beneficial for prediction than inference. If inference is the goal for the vintner and horticulturalists who seek to understand the properties that make good wines, the model with higher interpretability and the second highest accuracy is the Lasso regression model. While the PLS is more accurate, again it suffers from ease of interpretation. 

Thus with this in mind, the best model for inference with high accuracy is characterized by the below equation:

\begin{equation}
\begin{aligned}
\label{lasso_eq}
quality = 39.37 + 0.0823 * fixed\;acidity -0.981 * volatile\;acidity -0.405 * citric\;acid \\
-0.013 *residual\;sugar -1.075 * chlorides + 0.006 * free\;sulfur\;dioxide\\
- 0.002 * total\;sulfur\;dioxide - 37.09 * density +1.032 * sulphates + 0.256 * alcohol
\end{aligned}
\end{equation}

Whereas the best model for prediction is the boosted regression model. An example tree is show below:

```{r example_boost, echo=FALSE}
knitr::kable(example_boost, booktabs = TRUE,
             caption = "Example Boosted Regression Tree")
```

Applying the equation \ref{lasso_eq} the vintner can examine each of the variables independently and provide some degree of inference regarding the chemical levels that influence the quality of the red wine. For instance we see that sulfate content appears to have a strong positive influence on wine quality while having additional residual sugars reduces wine quality (as measured by the subjective wine quality score). In the hands of the vintner, these relationships can be explored or potentially exploited to produce a more consistent, higher quality wine. \linebreak

Turning to the classification method, the best overall classification method was Quadratic Discriminate Analysis. This is seen in both the overall accuracy as well in its ability to accurately classify each subcategory. While the other methods have lesser abilities to detect the good and poor quality wines, the QDA method showed the best accuracy in these two fields, which is very important for vintners when it comes to pricing and selling. The penalty of misclassifying a good wine as medium or a poor wine as medium/ good is severe as this may damage the reputation of the winery. From this analysis it is clear that QDA is the superior method for classification of red wines given this dataset. The priors and group means for the QDA are shown in the preceding figures.

```{r qda_priors, echo = FALSE}
knitr::kable(qda_priors, booktabs = TRUE,
             caption = "Priors used in Quadratic Discriminate Analysis")
```

```{r qda_means, echo = FALSE}
library(pander)
pander(qda_group_means, split.table =80, booktabs = TRUE,
             caption = "Group Means used in Quadratic Discriminate Analysis")
```

We would also like to address the fact that we have excluded two data points from the original data set. These were observations 1080 and 1082. These data points were excluded due to their being response outliers. We know this because their residual to leverage ratio is very large. If these points were included, the fitted models would be drastically different. For example, the flexible models would likely do better whereas the nonflexible models would do more poorly. Furthermore, we would also like to point out that several variable are highly correlated. For example fixed acidity, citric acid, and pH are all highly correlated. This would make sense to many people with a chemical background and to some mathematicians in hindsight. For instance pH is a measure of acidity. This collinearity is likely why LASSO shrinks several variables to zero and many more closely to zero. It is also likely why the PCR, PLS and ridge regression models produced similar processes while the full linear regressions suffers greatly.

As discussed, there existed some issues with the dataset. As we used a publically available dataset without indentifying details (wine name, winery name, etc) we could not further explore the cause of potential outlying values. Had this information been available we could have been more confident with the elimination of outliers and other discerning information.

The predictors, while loosely normal were not normal as evidence of a Shapiro Wilke test on all the predictors (all p values < 0.01). Log, square root and polynomial transforms were attempted to normalize the data but these transforms did not improve the normality of the predictors. Because of this fact we could have performed an advanced transformation to these values like a Boxcox transform, but this would have made interpretability of the resulting models much more difficult. As such these transforms were not used for sake of this analysis.

#Conclusion

The best method for prediction is the boosted regression model. The best method for inference is the Lasso regression model. The best method for classifying into high, medium, and low quality wine is the quadratic discriminant analysis technique. Two data points were found to be response outliers and were removed. The distributions of the predictor variables do not seem to have a serious effect on the fitted models. The highly correlated variables do have an effect on the fit of the models, depending on the strengths and weaknesses of the various model fitting processes.



