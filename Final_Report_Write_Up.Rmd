---
title: "Final Report for Red Wine Analysis"
author: "Ruiqiang Chen, Michael DeWitt, David Williams, Alex Vannoy"
date: "7/28/2017"
output: 
  pdf_document: 
    fig_caption: yes
    fig_height: 4
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ProjectTemplate)
library(ggfortify)
load.project()

(filenames <- list.files("src", pattern="*.R", full.names=TRUE))

for( a in 1:length(filenames)){
  on.exit(filenames[a])
  source(paste0(filenames[a]))
}
```

# Introduction

The purpose of this document is to report the proposed statistical models for classification of red wine bases on 11 predictors. The purpose of this analysis is to provide a model to the vinters in order for them to better predict the quality rating for their product. Analysis will be performing using both regression techniques and classification techniques.

# Description of Data
The data set provided is the Wine dataset from UC Irvine. It consists of `r nrow(red_wine_data_raw) ` with a total of `r ncol(red_wine_data_raw) ` predictors. These predictors include the following `r names(red_wine_data_raw)` with the quality feature being associated with the judgement of the individual wine's quality. Quality is the feature of interest for the dataset as the vinter is interested in judging the wine's quality through objective means rather than todays subjective method of averaging the 1-10 point judgment of tastetesters. The distribution of these different criteria can be seen below:
```{r echo=FALSE, warning=FALSE, message=FALSE}
red_wine_data_index <-red_wine_data_raw%>% 
  mutate(id = seq.int(nrow(red_wine_data_raw)))
as.data.frame(red_wine_data_index) %>% 
  melt(id.vars = "id") %>% 
  ggplot(aes(value))+facet_wrap(~variable, scales = "free_x")+geom_histogram()+
  geom_histogram(binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)))
```

The following are slightly right skewed: Fixed Acidity, Volatile Acidity, Citric Acid, , Free Sulphur Dioxide, Total Sulphur Dioxide, Sulphates, and Alcohol. Residual Sugar and Chlorides are heavily right skewed with density and pH appearing more normally distributed. Reviewing the individual components there appears to be a slight irregularity with total free sulfur dioxide. This can be seen in the histogram of this variable. 
```{r echo=FALSE }
as.data.frame(red_wine_data_factors) %>% 
  melt() %>%
  filter(variable == "free_sulfur_dioxide") %>% 
  ggplot(aes( value))+
  geom_histogram(bins = 30)+
  labs(
    title = "Histogram of Free Sulfur Dioxide",
    caption = "From UCI Wine Data Set"
  )+
  xlab("Free Sulfur Dioxide")
```
As well as the fit of thithat display high studentized residuals and leverage and thus should be considered for removal in the modeling process. These wines are 1080 and 1082.

```{r echo=FALSE}
autoplot(fit2)+
  labs(title = "Total Sulfur Dioxide")
```
These two wines have been removed from the clean dataset in order to be better predictors. The presence of these two wines may result in incorrect or inaccurate predictions. Ass we did not gatehr this dataset, we do not know if this information was incorrectly captured or if these values are real.

# Method
In order to understand the testing error of any of the modeling used the data was divided in testing and training data sets with which to train then models and then test and estimate the testing error. Seventy percent of the raw data was randomly selected and placed in the training set with the remaining 30% used in the testing data set.

##Regression

In order to select the best fit regression model several different modeling methods were tested. These include Laast Squares Regression, Ridge Regression, Lasso Regression, Principle Components Regression and Partial Least Squares Regression. For each of these methods the quality integer was the value that the model was attempting to predict. The data was divided into two sets, a training set to train the model and a testing set for model validation. We will now go deeper in the model generation process for each of these different modeling types and methods.

###Least Squares
The least squares regression method that was tested was the best subset selection. The methodology used to determine the best subset model was to first run cross validation on the training set in order to determine the number of predictors to include in the model. Once this analysis indicated that any added predictor after four variables were selected did not increase the accuracy of the model greatly using this cross validated method.  The training data was then used to determined the best subset of the linear model with three predictors. The best subset included:

####Residual Analysis
Here we need to make some plots against of the fit vs predictors and fit vs prediction to cross off that we considered our residuals

```{r, echo = FALSE, warnings= FALSE, message = FALSE}
print(linear_resid)
```
The residuals appear to have no distinct pattern which is a positive sign that there are not lurking relationships that have not been treated by the modeling.


###Ridge Regression
Ridge regression was performed on the dataset as well. Cross validation was performed on the training data set to determine the optimum value for lambda for the ridge regression. This lambda, `r round(bestlam_ridge,3)` was then using in a ridge regression model with the testing dataset.

###Lasso Regression
Lasso regression was used with cross validation on the data set. Cross validation was used to determine the best lamba which was `r round(bestlam_lasso,3)`. As a function of the lasso regression only pH was shrunk to zero with total sulphur dioxide and free sulphur dioxide being spring to near zero.

###Principal Components Regression
Principal compents regression was used. BAsed on the analysis of the principal components, the first nine principal compnents were used to be trained on the training set. This was done because 90% of the variation couyld be explained by these first nine components. 

###Partial Least Squares Regression

### Model Selection
```{r warning= FALSE, echo = FALSE}
print(MSE_plot)
```


### Residual Analysis

##Classification
For classification purposes the wines were segregated in to three different classes. These classes include "good" (quality >7), "medium" (quality between 4 and 7) and "poor"(quality < 4).

### Model Selection

### Residual Analysis

##Comparison of Models
```{r echo=FALSE, message=FALSE, warning=FALSE}
print(classification_plot)
```


#Discussion

#Conclusion

#Issues
